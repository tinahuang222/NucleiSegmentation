{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import ast\n",
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import radius_graph\n",
    "import progressbar\n",
    "from tqdm.notebook import tqdm\n",
    "import importlib\n",
    "import generate_graph as gg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_path = '/Users/akre96/Data/BE_223B/tiles_rois/normalized/'\n",
    "centroids_path = '/Users/akre96/Data/BE_223B/tiles_rois/centroids/'\n",
    "features_path = '/Users/akre96/Data/BE_223B/tiles_rois/nucleus_features/'\n",
    "labels_path = '/Users/akre96/Data/BE_223B/tiles_rois/dataset.csv'\n",
    "tensor_data_path = '/Users/akre96/Data/BE_223B/tiles_rois/graph_data.pkl'\n",
    "feat_rank_path = '../Feature_selection/logistic_regression_coefficients.csv'\n",
    "\n",
    "labels = pd.read_csv(labels_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [01:03<00:00, 15.59it/s]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(gg)\n",
    "data_sets = []\n",
    "feat_subset = None\n",
    "n_features = 64\n",
    "data_sets = gg.create_data_set(\n",
    "    features_path,\n",
    "    labels_path,\n",
    "    feat_rank_path,\n",
    "    n_features=n_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "tensor_data_path = '/Users/akre96/Data/BE_223B/tiles_rois/graph_data.pkl'\n",
    "tensor_data_path = tensor_data_path.split('.pkl')[0] + '_' + str(n_features) + '.pkl'\n",
    "with open(tensor_data_path, 'wb') as fp:\n",
    "    pickle.dump(data_sets, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Training/Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891 99 99\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "validation_pct = 0.1\n",
    "validation_size = int(len(data_sets) * validation_pct)\n",
    "\n",
    "train_set = data_sets[:-validation_size]\n",
    "test_set = data_sets[-validation_size:]\n",
    "print(len(train_set), len(test_set), validation_size)\n",
    "\n",
    "shuffle = False\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=shuffle, pin_memory=False)\n",
    "train_test_loader = DataLoader(train_set, batch_size=1, shuffle=shuffle, pin_memory=False)\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=shuffle, pin_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [02:17<00:00,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6916369199752808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import model as mod\n",
    "importlib.reload(mod)\n",
    "epochs = 1\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "model = mod.Net(64).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "model.train()\n",
    "\n",
    "\n",
    "\n",
    "for epoch in (range(epochs)):\n",
    "    i = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        data = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = loss_function(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if torch.isnan(loss):\n",
    "            break\n",
    "    print(loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Set\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "model.eval()\n",
    "x=[]\n",
    "y=[]\n",
    "TP=0\n",
    "FP=0\n",
    "TN=0\n",
    "FN=0\n",
    "\n",
    "preds=[]\n",
    "y_true=[]\n",
    "\n",
    "for data in train_test_loader:\n",
    "    mod_out = model(data)\n",
    "    pred = torch.argmax(mod_out[0])\n",
    "    \n",
    "    truth = data.y[0]\n",
    "    if pred == truth:\n",
    "        if truth:\n",
    "            TP+=1\n",
    "        else:\n",
    "            TN+=1\n",
    "    else:\n",
    "        if truth:\n",
    "            FN+=1\n",
    "        else:\n",
    "            FP+=1\n",
    "    x.append(truth.item())\n",
    "    y.append(pred.item())\n",
    "    preds.append(mod_out[0].tolist())\n",
    "    y_true.append(np.eye(2)[truth])\n",
    "\n",
    "total = TP+FP+FN+TN\n",
    "print('Sensitivity:', TP/(TP+FN))\n",
    "print('Specificity:', TN/(TN+FP))\n",
    "print('Accuracy', (TP+TN)/(total))\n",
    "print('AUC', roc_auc_score(y_true, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set\n",
    "model.eval()\n",
    "x=[]\n",
    "y=[]\n",
    "TP=0\n",
    "FP=0\n",
    "TN=0\n",
    "FN=0\n",
    "\n",
    "preds=[]\n",
    "y_true=[]\n",
    "\n",
    "for data in test_loader:\n",
    "    mod_out = model(data)\n",
    "    pred = torch.argmax(mod_out[0])\n",
    "    \n",
    "    truth = data.y[0]\n",
    "    if pred == truth:\n",
    "        if truth:\n",
    "            TP+=1\n",
    "        else:\n",
    "            TN+=1\n",
    "    else:\n",
    "        if truth:\n",
    "            FN+=1\n",
    "        else:\n",
    "            FP+=1\n",
    "    x.append(truth.item())\n",
    "    y.append(pred.item())\n",
    "    preds.append(mod_out[0].tolist())\n",
    "    y_true.append(np.eye(2)[truth])\n",
    "\n",
    "roc_auc_score(y_true, preds)\n",
    "total = TP+FP+FN+TN\n",
    "print('Sensitivity:', TP/(TP+FN))\n",
    "print('Specificity:', TN/(TN+FP))\n",
    "print('Accuracy', (TP+TN)/(total))\n",
    "print('AUC', roc_auc_score(y_true, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4537dfa60f4542b3eb0b298b832816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 1\n",
      "Sensitivity: 0.78\n",
      "Specificity: 0.6938775510204082\n",
      "Accuracy 0.7373737373737373\n",
      "Loss 0.5459474325180054\n",
      "AUC 0.7738775510204081\n",
      "\n",
      "Fold: 2\n",
      "Sensitivity: 0.9038461538461539\n",
      "Specificity: 0.6382978723404256\n",
      "Accuracy 0.7777777777777778\n",
      "Loss 0.5307608246803284\n",
      "AUC 0.8846153846153846\n",
      "\n",
      "Fold: 3\n",
      "Sensitivity: 0.8431372549019608\n",
      "Specificity: 0.4166666666666667\n",
      "Accuracy 0.6363636363636364\n",
      "Loss 0.6235640048980713\n",
      "AUC 0.6830065359477124\n",
      "\n",
      "Fold: 4\n"
     ]
    }
   ],
   "source": [
    "fold_cross = 10\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "validation_pct = 0.1\n",
    "validation_size = int(len(data_sets) * validation_pct)\n",
    "\n",
    "performance_dict = {\n",
    "    'TP': [],\n",
    "    'TN': [],\n",
    "    'FP': [],\n",
    "    'FN': [],\n",
    "    'total': [],\n",
    "    'Accuracy': [],\n",
    "    'Sensitivity': [],\n",
    "    'Specificity': [],\n",
    "    'AUC': []\n",
    "}\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for i in tqdm(range(fold_cross)):\n",
    "    print('\\nFold:',i+1)\n",
    "    test_set = data_sets[i*validation_size:(i+1)*validation_size]\n",
    "    train_set = [t for t in data_sets if t not in test_set]\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=1, shuffle=True)\n",
    "    \n",
    "    # Train\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    model = Net(len(feature_cols_subset)).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "    model.train()\n",
    "\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        i = 0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(batch)\n",
    "            loss = loss_function(out, batch.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    # Test\n",
    "    model.eval()\n",
    "    x=[]\n",
    "    y=[]\n",
    "    TP=0\n",
    "    FP=0\n",
    "    TN=0\n",
    "    FN=0\n",
    "    y_true=[]\n",
    "    preds=[]\n",
    "    for data in test_loader:\n",
    "        mod_out = model(data)\n",
    "        pred = torch.argmax(mod_out[0])\n",
    "        truth = data.y[0]\n",
    "        if pred == truth:\n",
    "            if truth:\n",
    "                TP+=1\n",
    "            else:\n",
    "                TN+=1\n",
    "        else:\n",
    "            if truth:\n",
    "                FN+=1\n",
    "            else:\n",
    "                FP+=1\n",
    "        x.append(truth.item())\n",
    "        y.append(pred.item())\n",
    "        preds.append(mod_out[0].tolist())\n",
    "        y_true.append(np.eye(2)[truth])\n",
    "    total = TP+FP+FN+TN\n",
    "    Sensitivity = TP/(TP+FN)\n",
    "    Specificity = TN/(TN+FP)\n",
    "    Accuracy = (TP+TN)/(total)\n",
    "    AUC = roc_auc_score(y_true, preds)\n",
    "    print('Sensitivity:', Sensitivity)\n",
    "    print('Specificity:', Specificity)\n",
    "    print('Accuracy', Accuracy)\n",
    "    print('Loss', loss.item())\n",
    "    print('AUC', AUC)\n",
    "    performance_dict['TP'].append(TP)\n",
    "    performance_dict['TN'].append(TN)\n",
    "    performance_dict['FP'].append(FP)\n",
    "    performance_dict['FN'].append(FN)\n",
    "    performance_dict['Sensitivity'].append(Sensitivity)\n",
    "    performance_dict['Specificity'].append(Specificity)\n",
    "    performance_dict['Accuracy'].append(Accuracy)\n",
    "    performance_dict['total'].append(total)\n",
    "    performance_dict['AUC'].append(AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_df = pd.DataFrame.from_dict(performance_dict)\n",
    "perf_df[['Accuracy', 'Sensitivity', 'Specificity', 'AUC']] = perf_df[['Accuracy', 'Sensitivity', 'Specificity', 'AUC']] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9,8))\n",
    "sns.set_context('poster')\n",
    "perf_df['Fold'] = perf_df.index\n",
    "melt_df = perf_df[['Fold', 'Accuracy', 'Sensitivity', 'Specificity', 'AUC']].melt(var_name='Metric', id_vars='Fold')\n",
    "sns.swarmplot(\n",
    "    x='Metric',\n",
    "    y='value',\n",
    "    hue='Fold',\n",
    "    data=melt_df,\n",
    "    ax=ax,\n",
    "    s=10\n",
    ")\n",
    "ax.legend().remove()\n",
    "ax.set_ylim((-5,105))\n",
    "ax.set_xlabel('')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_df[['Metric', 'value']].groupby('Metric').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('venv': venv)",
   "language": "python",
   "name": "python37364bitvenvvenv20fd20bed1f24141af3e87448b4a1145"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
